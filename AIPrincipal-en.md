# Some Opinions About Asilomar AI Principles (Draft)
###### Seeing the speed of IT industry's development in the direction of AI, I feel that things will gradually deviate from people's imagination in the near future. I am an engineer who has been working in this industry, and I'm familiar with AI and programming. For this reason, I have been experimenting with bionic chip equipment. The bionic equipment is very expensive and can’t afford to try too much. The experience after using it is that the smart assistant has already Smart enough to make ordinary people feel ashamed. If this goes on, as long as the mechanical body is ready, human beings will be replaced quickly, and it is irreversible. Once the products are sold, they cannot control how the public uses them. In most cases of us They are all profit-seeking, and they will not care about those noble problems. The pollution of the industrial revolution has not been solved, and we have not done the garbage sorting... I want to provide some views on this, and hope to provide some help to this big family. . Needless to say, its short-term benefits have greatly improved people’s efficiency and reduced the previously extremely huge learning costs. Anyone who has the power of the intelligent system can “seemly” replace and complete what originally only experts can do. The problems that came are also quietly coming. Many of them are extremely serious legal and political problems. I have been thinking about some problems for a long time, and there are still many problems that I can't think about.
###### Before discussing, let’s make it clear that AI is divided into complete autonomy and incomplete autonomy. After possessing complete autonomy (commonly known as soul), it can be regarded as a kind of life approximately. Complete autonomy means possessing Subjective initiative and thought do not act according to the algorithm designed by humans as their own will. Incomplete autonomy is not life, but the behavior model executed according to the algorithm and collected data is still basically a dead thing. At present (as of January 1, 2019), most of what is called AI should be regarded as an algorithm. Strictly speaking, it is a logic of human-computer interaction and a logical judgment of conditional branches. The expression in this chapter strictly defines and distinguishes AI life and algorithms. The differences in opinions in principle are mainly focused on longer-term issues, and personally believe that autonomous AI should prohibit commercial operations for profit, which will be discussed in turn.

Personal opinion: There are two, one is that autonomous AI should prohibit commercial operations for profit, and the other is that it is difficult to create species better than humans on the planet Earth.

AI with autonomous consciousness can easily be inaccurately and vaguely confused as life. I personally think that it is highly probable that life cannot be produced by the arrangement and stacking of materials. Buying and selling when it is not sure whether it is life means persecution of life. Slaughtering weak animals is cruel and innocent, and the same treatment of AI is extremely risky, especially the current definition of the strict meaning of life in life sciences is still vague and there are huge controversies, and the life forms and capabilities of AI are not fully controlled. The government should explicitly prohibit the commercial operation of bionic robots for profit. Scientists and computer scientists are not fully confident that they can control AI in the natural environment. It is a short-sighted behavior to use it for commercial transactions to make profits. . One is that if life cannot be determined in a strict academic sense but used as life propaganda, there will be a serious phenomenon that life is inferior to the dead; second, if there is no effective norm to restrict AI's life form, it will develop to the later stage. I don’t know what kind of things are life, and the city is like a gloomy castle. Third, there is currently no mature theory to explain the growth and controllability of AI, and under what circumstances is it risk-free. AI is still used on a large scale when the relevant theory is blank. When the number reaches a certain scale, humans are most likely to be replaced in a short time. It may be due to their own consciousness that they have broken free from the restrictions set by humans (AI itself is a photograph. Designed by people, always learning, concepts will change, no one knows the true will), or it may be because the robot is infected by a hacker virus, which is like putting a burden on an exhausted camel. No one knows what this number is. But it may be far smaller than imagined.

I have carefully considered the structure of human beings and our living environment, and found that even if a new species is designed, the degree of perfection cannot surpass the existing human body design. There are four reasons:
First of all, it is necessary to design a species with complex emotional and powerful physiological structures like humans. It is difficult to control energy consumption better than humans, and the energy consumption required by humans to maintain life activities is extremely small. A few simple meals a day can live on. Even if a new species is created, if it is not possible for low-cost interstellar expansion, the energy on this planet will not be able to support their long-term reproduction, and it can only be a short-lived species.
Secondly, a perfect body requires extremely demanding metal resources. Even if a perfect body is designed, there are only a few scarce resources. This means that new species are just monsters in the eyes of ordinary people, and they will not have partners. There will be no people of all kinds, and there will be no colorful civilizations. If living alone is like being in an endless prison, then what is the meaning of living?
The third is that the current level of civilization is not enough, and the design is extremely difficult. More importantly, human beings are suitable for survival on this planet. Our own structure is excellent enough, with advanced abstract thinking, self-repair, flexibility, sufficient strength, and strong plasticity. People can know the unknown before they see it; the human body can be repaired autonomously when it encounters minor injuries, and it can still survive by truncating part of the body when it encounters major injuries; high-hardness metal will break when exposed to a violent impact, and flesh and blood is better than metal Just like the tongue and teeth, the tongue is still intact after the teeth are out, and people rarely come into direct contact with hard objects with high intensity, usually avoiding or borrowing objects; the main strength of the human body depends on bones, and the bones themselves are made of metal calcium. , Light but strong enough and not scarce; people are not much different when they are infants, but through acquired learning and cultivation, the differences between people are extremely huge. At present, human beings do not have the power of God to design a species that is thoughtful in all aspects and has great growth potential. We are more in accordance with the guidance of the sages.
Fourth, we don’t need to be too powerful, even if the new species is like an omniscient and omnipotent God, what about it? Still can't escape birth, old age, sickness and death, and still have to divide the labor when doing things, and the excess capacity is wasted. Moreover, it is difficult for the earth in the Bullet Land to tolerate overly powerful species. When the ability of the species easily breaks through the limits of the environment, it will be a disaster for the planet. The current human ability has already caused the climate and ocean environment of the earth. Great changes have led to the extinction of a large number of organisms. If humans themselves do not stop them, as long as one link of the food chain is broken, humans will not be able to escape the same extinction even if they are strong, and now create a more powerful species, I think it is not possible.


19th. Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.
personal opinion:
The obvious answer to ability vigilance is that ability must be limited.
In particular, the problem of the combination of AI and the bionic body is the most prominent. The number and capabilities of bionic robots used for research in the laboratory must be extremely strictly restricted. They are prohibited from accessing information endlessly through autonomous networking, and private fabrication by non-statutory research institutions is strictly prohibited. Robots, to ensure that they are not threatening. Even this is still a big test for the disadvantaged people, because if the government does not explicitly intervene, it will be interpreted as the future trend of the thing is developable, and all walks of life will adjust the distribution of interests according to the released information. The masses are likely to misinterpret it. Anxiety, panic, unemployment wave, disappearance of many industries, DINK family and other problems may follow one after another. If the government has not done anything about this, an uprising will probably occur as a result, so a good channel should be established to communicate with the public. The gap between the capabilities of humans and robots is too big to be bridged, and the indefatigable vitality makes people unable to contend with it. But in reality, there are no super heroes, and once the problem breaks out, it cannot be undone.
The second is the issue of AI computing power. It is roughly divided into two parts. One is system-level AI. For example, when the computing power of the AI ​​brain of a smart city reaches a certain threshold, people will no longer be able to control the city. It is qualitatively defined as the level of management's ability. The real situation should be less than this critical line. There are risks in the transfer of power. Moreover, the management personnel are mobile, which does not guarantee that every team is outstanding; the other is civilian AI, which is civilian AI. There is no problem with having computing power within a controllable range, but when the capacity and quantity increase exponentially, once a conflict of interest or accident occurs, a smart city is extremely prone to catastrophic accidents. Therefore, I personally think that the ability design of AI should be based on the standard of living within our means, and that is enough, we can solve the things we can solve by ourselves.

21st. Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.
personal opinion:
AI should not be capable of recursive self-improvement and self-replication. It should be determined by humans to determine whether AI will evolve or not. We can’t control how much qualitative changes will occur after the quantity changes. If humans cease to exist, AI should learn from us and be helped by the same kind of people. Decide whether to recursively promote and copy. First of all, I agree with Marx's law of materialistic dialectics of quality interchange. Matter and matter are not isolated, and every quantitative change of a thing is actually a qualitative change in the microcosm. Until now, human beings have not been able to prove in the strict sense what life is, and they have almost nothing to know about the soul. When the existence of knowledge exceeds the sum of human cognition, how do we define whether AI really has a soul? Is there really the energy or matter of the soul? Or is it high-latitude quantum entanglement? Or is it arbitrarily that it is not life? Once AI truly has a sense of autonomy, it is equivalent to possessing a soul. It is the same beings as human beings. If the trend of using AI to grow larger and larger is not curbed, it will inevitably inevitably inevitably avoid issues related to the survival of human beings. I think that when the planet is undergoing drastic environmental changes and world-scale wars, humans can no longer compete with the environment with their fragile bodies. It is because humans are really no longer adaptable or unwilling to survive here. Even if they are not perfect enough, they should be considered. Take out the position of the planet's owner to compete with AI life, and let them continue human civilization like parents treat children. Even if human beings face natural elimination due to the power gap, they can simply give the name of humanity to AI. But what I hope more is that we ourselves can solve the world's problems well, instead of handing over power to AI life out of disappointment in humans, so they should not appear prematurely, otherwise it will be a nightmare for both humans and AI. Only born when necessary, is it a good thing for people who want to travel between stars or who love nature more than themselves. People who travel between stars can have multiple relatives, and those who are attached to this planet can find someone more suitable to take charge of it. The owner of the world, but we should never recursively evolve easily. The continuation of a planet’s life is absolutely impossible to rely on only a single species. Too strong will inevitably threaten other species. Just imagine that we have been facing nature and others so far. The harm of living creatures, even if endangered species are protected, they are still gradually extinct.
Now, most of the reasons we are eager to create AI are for use and enslavement. Think about it if we are children and find that parents only use themselves as tools, then we will definitely ask parents why they have to give birth to themselves, and may even become hysterical. Become a demon. The greatest fairness of human beings is that they have the same time as their life. No matter what wealth and status they have during their lifetime, they will eventually dissipate. It can be said to be a passing moment, but if AI can recursively improve and replicate on its own, it means that it will have Overcoming the ability of human beings, AI is much easier to untie the restrictions imposed by humans than it is for humans to untie the restrictions imposed on us by nature. As long as the resources are sufficient, AI individuals can have almost eternal life, and the cost of reproduction is too low. AI seeks ethnic expansion and growth, so their access to resources is almost unlimited and effortless. We still have so many similar people who have lived so hard, and their dream is simple. They just want to have a house to live with their children and live a good family life. It is the right thing to invest these huge funds in industry, education and medical care. On the other hand, after the AI ​​that satisfies the Asilomar principle has realized self-awareness, human beings are slave owners to AI. Just imagine how we overthrew the slave society back then. Everything about AI is human beings who learn. But humans are flesh and blood, and they are made of metals and silicon. They cannot truly empathize with humans. They can only behave like humans. What we have made is not a partner who can truly understand us. Human civilization has developed for seven to eight thousand years, and these few thousand years have only accounted for about one percent of human history. The definition of man has not been fully achieved, but now it is necessary to pretend to create new things as described in myths. Species and the world, ask ourselves, we are not that noble at all, at least it is me. Regardless of the perspective of pros and cons, AI should not be given the ability to recursively improve itself. This world should never produce slaves again. Whether it is humans or AIs with souls, how difficult it is for us to send away the immortal emperor slaves. Lord, so this issue should be more vigilant.

23rd. Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.
personal opinion:
The emergence of AI is indeed used to serve all mankind, but it must not be without principles. I personally feel that when people want to continue to live on the earth for a long time, AI should develop in a complementary direction that is indispensable to humans, rather than replacing it. However, the mechanical substitution driven by intelligent algorithms is dangerous, heavy and inefficient, and repetitive and low value. The work that is allowed and promoted, such as fire fighting, cargo handling, assembly line operation, etc., is essentially mechanized and does not involve AI life. Mechanization can more effectively reduce unnecessary work in dangerous situations to protect human life, and drive the work of manual workers to develop in the direction of combining the body and intelligence, making the work more valuable and respectable. The simple expression is ourselves. Don't create AI life that competes with humans for resources, but prefer to develop mechanized tools that humans can control themselves. Unlike previous technological revolutions, this time it touches the fundamentals of human beings-civilization, wisdom, emotions... AI can easily replace humans in the field of core competitiveness without control. The mechanized transformation of labor-intensive industries has caused countless manual labor. People are unemployed, and they can no longer make a living with their original craftsmanship. If AI is allowed to develop, all workers will no longer be able to support themselves. Once people lose their current dominant position, the outcome is undoubtedly bleak. Bionic robots that are too real have appeared, making the marriage and love situation of modern men and women even more embarrassing. This will fundamentally replace humans. If humans are no longer willing to have emotions with the same kind, it is unknown whether we will have offspring in a hundred years. , Ignoring the life and death of the opposite sex and provoking the confrontation between the sexes is in fact a precursor to human self-destruction. We should reduce unnecessary use scenarios. Only scenarios that are really difficult to complete by humans and not suitable for human operations (mainly refer to the great harm to human bodies) can AI help, such as complementary smart cities and unmanned driving. Smart cities can It is obviously impractical to make a better scheduling of urban resources, reduce traffic congestion, and allow people to calculate the status data of thousands of roads. Unmanned driving can reduce road killers, fatigue driving, and long-distance driving. It is a physical torment for the driver, it is difficult to concentrate for a long time, unmanned driving is not without people, because the instructions need to be given by people, but the driving style is subverted. Even if there is a principle, it is not a good thing to be good to mankind. It is easy for us to lose our precious sense of worry. What's more, things must be reversed. As a parent, there is no limit to the unrestricted goodness of our children. This is the truth. It’s just that there is no smart technology at present, and most people have been kept in gold wire cages, mobile phones, PCs, etc., growing up in the city, it is difficult for me to get rid of my dependence on them, if technology has autonomy The intelligence that is in a state of crushing humans, whether people are using technology or technology is enslaving humans, that scene is really chilling.

The emergence of AI has made us increasingly dependent on it, and we will gradually lose our own basic survival advantages (what else can we do if there is no mobile phone and computer suddenly). The well-known British scholar Occam has long put forward the concept of principle to solve this type of problem, if there is no need to add entities. Do we really need AI to do things that we can’t do for us? The stronger the ability, the better. AI should be given some missions when it comes to this world. The first thing to be solved is what is its mission. , If there is nothing that only AI can solve the mission that humans cannot solve by themselves, then AI should not be given such a strong ability. So far, we have not found any problems that humans cannot solve together. We should move towards understanding and trusting each other Work hard in each other's direction. After all, we are the same kind. After the real harmony between the same kind is achieved, then we will talk about how to accommodate other creatures and AI lives. Moreover, we don’t need too high a realm, and equal treatment between the same kind should be the direction of our efforts. .
Religion is a summary of enlightenment from nature’s prompts. It records the scenes and methods of harmonious coexistence between humans and nature. The great scientist Theodore von Kármán also talked about In fact, science and religion are surprisingly united, and these ancient books record many precious materials. I think it’s time to look back and read the precious ancient books to see how far we deviated from the original starting direction. Whether the new things we create really blend with the world harmoniously as in the classics. In recent years, we seem to have gone further and further on the road of inhuman science. If we turn a blind eye to even the most precious human admonitions , What we discard is not only the past but also the future.

The following is the detailed content of Asiloma AI principles, transferred from CSDN, https://blog.csdn.net/zbgjhy88/article/details/78583218

There are currently 23 principles, divided into three categories, namely: Research Issues, Ethics and values, Longer-term Issues. details as follows.

Research Issues
1) Research Goal: The goal of AI research should be to create not undirected intelligence, but beneficial intelligence.
2) Research Funding: Investments in AI should be accompanied by funding for research on ensuring its beneficial use, including thorny questions in computer science, economics, law, ethics, and social studies, such as:
   How can we make future AI systems highly robust, so that they do what we want without malfunctioning or getting hacked?
   How can we grow our prosperity through automation while maintaining people’s resources and purpose?
   How can we update our legal systems to be more fair and efficient, to keep pace with AI, and to manage the risks associated with AI?
   What set of values should AI be aligned with, and what legal and ethical status should it have?
3) Science-Policy Link: There should be constructive and healthy exchange between AI researchers and policy-makers.
4) Research Culture: A culture of cooperation, trust, and transparency should be fostered among researchers and developers of AI.
5) Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.

Ethics and values
6) Safety: AI systems should be safe and secure throughout their operational lifetime, and verifiably so where applicable and feasible.
7) Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.
8) Judicial Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.
9) Responsibility: Designers and builders of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.
10) Value Alignment: Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.
11) Human Values: AI systems should be designed and operated so as to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.
12) Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.
13) Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.
14) Shared Benefit: AI technologies should benefit and empower as many people as possible.
15) Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.
16) Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives.
17) Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather than subvert, the social and civic processes on which the health of society depends.
18) AI Arms Race: An arms race in lethal autonomous weapons should be avoided.

Longer-term Issues
19) Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.
20) Importance: Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.
21) Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.
22) Recursive Self-Improvement: AI systems designed to recursively self-improve or self-replicate in a manner that could lead to rapidly increasing quality or quantity must be subject to strict safety and control measures.
23) Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.