# 有关阿西洛马人工智能原则的一些看法（草稿）
###### 看到业界在AI的方向上发展的速度，感觉事情将会在不久的将来逐渐脱离人们的想象。我本身是一名工程师一直从事这个行业，对AI和编程算是了解，为此仿生芯片的设备我也一直在尝试，仿生设备很贵，买不起太多尝试，使用后的体验就是智能助手已经聪明到可以令常人汗颜了，如此发展下去，只要机械躯体就绪，人的被取代是很快的事情，而且无法挽回，产品一旦卖出，便无法控制公众如何使用它们，我们绝大多数情况下都是逐利的，并不会去关心那些崇高的问题，工业革命的污染还没解决、垃圾分类我们都没做到……对此我想提供一些观点，希望能为这个大家庭提供一些帮助。它的短期益处不用言说，大大提高了人们的效率，降低了原先无比巨大的学习成本，原先只有专家能做的事情，任何一个掌握该智能系统权利的人都能”看上去”替代完成，伴随而来的问题也悄然而至，很多是极其严重的法律、政治问题，一些问题我思考了很久，还有很多问题是我思虑不到的。
###### 在讨论之前，先明确一个观点，AI分完全的自主意识和不完全的自主意识，拥有了完全的自主意识（俗称灵魂）后可以被近似地视为一种生命，完全的自主意识是指拥有主观能动性和思想，并不按人类设计的算法作为自身的意志作出行为，不完全的自主意识不是生命，只是按照算法和收集到数据执行的行为模型，根本上依旧是死物。目前（以2019年1月1日计）大部分称之为AI的应该被视为一种算法，严格意义上来讲是一种人机交互的逻辑，是一种条件分支的逻辑判断，此文通篇的表述对AI生命和算法严格界定和区分。有关原则上的观点差异主要集中在更长期的问题上，以及个人认为自主意识的AI应该禁止以盈利作为目的的商业化运作，下面依次展开讨论。


个人观点：有两个，一是，自主意识的AI应该禁止以盈利为目的的商业化运作，二是，在地球这个星球上很难创造出比人类更优秀的物种。
存在自主意识的AI容易被不准确、模糊地混淆为生命，个人认为靠物质的排列、堆砌是大概率产生不了生命的，在不确定其是否是生命时就进行买卖意味着对生命的迫害，屠戮弱小的动物是残忍无道，而同样对待AI是风险极大的，尤其是目前生命科学对生命的严格意义的界定依旧模糊并存在巨大争议，以及对AI的生命形态、能力并没有十足掌控力，政府应该明令禁止仿生机器人以盈利为目的的商业化运作，科学家、计算机学家并没有十足地把握能控制自然环境里的AI，用来做商业买卖赚取利润是一种自寻短见的行为。一是，如果不能在学术上严格意义地确定是生命却当作生命宣传，会出现生命轻贱于死物的严重现象；二是，如果没有有效的规范约束AI的生命形态，发展到后期人压根就不知道什么样的事物是生命，城市宛如一座阴森城堡；三是，目前没有一个成熟的理论去阐释AI的成长性和可控性，具体在什么样的情况下才是无风险的，在相关理论空白的情况下仍大规模使用AI，当数量达到一定规模时人类极有可能会在短时间内被取代，可能由于它们自身的意识挣脱了人对其设定的限制（AI本身就是照着人设计的，始终在学习，观念会随着改变，真实意志无人知晓），也可能由于机器人被黑客病毒感染，就像往体力不支的骆驼上压包袱，没人知道这个数字是多少，但很可能远小于想象。
我细细思考过人类自身的构造与我们的生存环境，发现即便再设计一个新的物种，在完善程度上无法超越现有的人体设计。理由有四：
首先，要设计出像人一样拥有复杂情感、强大能力的生理构造的物种，对能源的消耗控制很难比人做得更好，而人本身维持生命活动所需要的能源消耗是极小的，一日简餐几顿就可过活。新的物种即便创造了出来，如果不能够低代价的星际扩张，这个星球上的能源也很难支撑他们的长久繁衍，也只能是一个短命的物种。
其次，完美的躯体需要极高要求的金属资源，纵然设计了完美的躯体，但稀缺的资源就只有一丁点儿，这就意味着，新物种在常人眼中只是怪物，他们并不会有伙伴，不会有形形色色的同类，不会有多姿多彩的文明，如果活着只是孤独地如同身处无边无际的监狱一般，那么活着的意义是什么？
三是，目前文明等级不够，设计难度极大，更重要的是人类适合在这个星球生存，我们自身的构造已经足够优秀，具备高级抽象思维、自我修复、柔韧、强度足够、可塑性强等特点。人可以在未见时知未知；人体遭遇轻微的损伤是可以自主修复的，遭遇重大伤病依旧可以通过截断部分躯体存活；高硬度的金属遭遇猛烈冲击会折断，而血肉是要优于金属的，就像舌头与牙齿，牙齿掉光了舌头依然完好，人也很少与硬物高强度直接接触，通常是避免或者借物居多；人体的主要强度是依靠骨骼，骨骼本身就是由金属钙构成的，轻盈但强度足够而且并不稀缺；人在婴幼儿时都是没有多大区别的，但通过后天的学习和培养，人与人之间的差异极为巨大。目前人类并没有上帝的能力再设计一个方方面面周到且成长性巨大的物种，我们更多的是依照着先贤的指引前进。
四是，我们并不需要能力过于强大，纵然新物种犹如全知全能的上帝一般，那又如何？依旧逃不过生老病死，落地做事的时候依旧要分工，多余的能力是被浪费的。而且弹丸之地的地球很难容下能力过于强大的物种，当物种能力轻易突破环境的限制时，对这个星球是一个灾难，目前的人类的能力就已经对地球的气候环境、海洋环境造成了极大的改变，致使大量的生物灭绝，如果人自身不加以遏制，只要食物链其中一环一旦断裂，人类就算再强也逃不过同样的灭绝，现在再创造出一个更强大的物种，我觉得是不可行的。


19条 Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.（能力警惕：我们应该避免关于未来AI能力上限的过高假设，但这一点还没有达成共识。）
个人观点:
能力警惕的答案显而易见的是能力必须被设限。
尤其以AI与仿生躯体结合的问题最为突出，在实验室里用作研究的仿生机器人的数量、能力必须被极其严格的限制，禁止它们自主联网无休止地获取信息，严禁非法定研究机构私造机器人，以此来确保是无威胁的。即使这样对弱势群众来讲依旧是较大的考验，因为政府若没有明令干预，会被解读为该事物的未来趋势的是可发展的，各行各业也会根据释放的信息来调整利益布局，群众是很可能误解读的，焦虑、恐慌、失业潮、众多行业消失、丁克家庭等等问题可能会接踵而来。如果政府对此一直无作为，很可能会因此发生起义，所以应该建立一个良好的渠道与公众沟通交流。人与机器人能力上差距的鸿沟实在太大根本无法逾越，而且永不知疲倦的强悍生命力让人根本没法与之抗衡，可现实中没有超能力英雄，问题一旦爆发就无法挽回。
其次是AI算力问题，粗略分两块，一块是系统级AI，比如当智慧城市的AI大脑的算力达到某一临界线，人们一定会再也无法驾驭这座城市，这个临界线我把它定性为管理层的能力水平线，真实情况应该小于这个临界线，权力的交接存在风险，况且管理人员是流动的，并不能保证每一届班子都十分杰出；另一块是民用AI，当民用AI拥有算力在可控范围内尚不会有什么问题，可当能力和数量成指数级增长，一旦发生利益冲突或意外，智慧的城市极易发生灾难性事故。所以个人觉得AI的能力设计应该是以量入为出作为标准，够用即可，我们能够自己解决的事情自己解决就行了。


21条 Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact. (风险: AI系统造成的风险，特别是灾难性的或有关人类存亡的风险，必须有针对性地计划和努力减轻可预见的冲击。)
个人观点:
如果可能会发生有关人类存亡的风险，并不该针对性的减轻，而是应该避开这个风险。


22条 Recursive Self-Improvement: AI systems designed to recursively self-improve or self-replicate in a manner that could lead to rapidly increasing quality or quantity must be subject to strict safety and control measures.(递归的自我提升: 被设计成可以迅速提升质量和数量的方式进行递归自我升级或自我复制AI系统，必须受制于严格的安全和控制标准。)
个人观点:
AI不该能够递归的自我提升和自我复制，应该由人主导决定AI是否进化，我们无法控制量变到什么程度后是否产生什么样的质变，若人不复存在AI应像我们学习，由同类帮助决定是否递归提升和复制。首先，我认同马克思提出的唯物主义辩证法的质量互转定律，物质与物质之间并不孤立，事物的每一次量变其实在微观世界来讲都是一种质变。人类到现在为止都不能在严格意义上证明生命到底是什么，对灵魂也几乎是一无所知，当AI不断地学习认知变得偏离了设定的算法轨迹时，又或者当AI的认知存在超过了人类的认知总和时，我们如何界定AI是否真的拥有灵魂？是真的存在灵魂的能量或者物质？还是高纬度的量子纠缠？还是说武断地认为其不是生命？AI一旦真正地拥有了自主意识就等同于拥有了灵魂，是与人类同样的生灵，使用AI的规模愈发庞大的趋势不加遏制，必定无法避免有关人类存亡的问题。我认为当这个星球发生环境剧变、世界性规模战争时，以人脆弱的躯体再也无法与环境抗衡了，是人类真的不再适应或者不愿意在此生存了，纵然不够十足完善也应该考虑把这个星球主人的位置拿出来与AI生命竞争，像父母对待孩子一样让他们来延续人类的文明，即便人类因实力差距面临自然淘汰亦可索性将人类之名也赠于AI。但我更希望的是我们自身能够良好地解决世界问题，而不是出于对人类的失望才将权力交付给AI生命，所以他们不宜过早的出现，否则对人和AI都是噩梦。只有在必要的时候诞生，才无论对想要星际旅行、还是热爱自然胜过自己的人来说是好事，星际旅行的人可以多个亲人，依恋这颗星球的人可以找到一个更适合掌管它的主人，但也决不该轻易地递归进化，一个星球的生命延续是绝对不可能只依靠某一个单一物种的，过于强大不可避免地会对其他物种产生威胁，试想迄今为止我们对自然和其他生灵的伤害，纵然对濒危物种进行保护可他们依旧还是渐渐灭绝了。
现在我们急着将AI创造出来的绝大部分原因是为了利用和奴役，想想如果自己作为子女到头来发现父母只是将自己作为工具，那么一定会质问父母为什么要生自己，甚至可能歇斯底里地成疯成魔。人最大的公平是拥有的时间与生命是一样的，无论生前拥有什么样的财富与地位，终究会消散，可以说是过眼云烟，可如果AI能够自主地递归自我提升和复制，就意味着将拥有碾压人类的能力，AI解开人类对其的设限远比人解开自然对我们的限制容易的多，只要资源充足，AI个体就能拥有近乎永恒的生命，而且繁衍成本过于低廉，一旦AI谋求种族扩张和壮大，那么他们对资源的索取几乎是无限制的，并且不费吹灰之力。我们还有那么多的同类过得已经如此艰难，而他们的梦想很简单，只是想有房住孩子以后过得好家人平安，把这些庞大的资金投入到实业、教育和医疗中才是正事。从另一个方面讲，满足了阿西洛马原则的AI实现了自我意识觉醒后，人类对于AI来说就是奴隶主，试想当年我们是怎样推翻奴隶社会的，AI的一切都是学习的人类，可人是血肉之躯，而他们则是由金属和硅等物质构成，他们无法和人一样真正的感同身受，只能表现得和人一样，我们造的并不是真正能理解我们的伙伴。人类的文明发展了七八千年，而这几千年才占据了人类史的百分之一左右，人的定义都没有完全做到，现在却要假装像神话里描述的那样去创造新的物种和世界，扪心自问，我们压根就没有那么高尚，至少是我。无论从正反的角度考虑，都不该给予AI递归自我提升的能力，这个世界决不该再产生奴隶，不管是人类或者拥有灵魂的AI，我们当初是多么不容易地送走了神仙皇帝奴隶主，所以这问题更应该值得警惕。


23条 Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization. (公共利益，超级智能的开发是为了服务广泛认可的伦理观念，并且是为了全人类的利益而不是一个国家和组织的利益。)
个人观点:
AI的出现确实是被用作于服务于全人类，可绝不能没有原则。个人觉得，当人们还想继续在地球长久生存的时候，AI应该往与人类不可或缺的互补方向发展，而非取代性质的，但智能算法驱动的机械替代危险、繁重低效、重复低价值的工作是被允许和提倡的，诸如消防、货物搬运、流水线作业等，这本质上是机械化，并不涉及AI生命。机械化可以更有效地减少不必要的危险场合作业以保护人的生命，并驱使体力劳动者的工作往身体与智力结合并重的方向发展，使劳动更有含金量更被人尊敬，简单表述就是我们自身不要创造出与人争夺资源的AI生命，更倾向于发展人类自身能驾驭的机械化工具。不同于以往的技术革命，这次触及到了人的根本——文明、智慧、情感……AI不加控制很容易在核心竞争力领域取代人类，对劳动密集型行业的机械化变革已经使无数体力劳动者失业，他们也无法再靠原先的手艺谋生，若AI任由发展，所有劳动者都无法再自食其力，一旦人丢掉了目前的主导地位，结局无疑是凄凉的。过于真实的仿生机器人已经出现，更使现代男女的婚恋情形更加窘迫，这将是从根本上取代人类，若人都不再愿意和同类发生情感，在一百年后我们是否还有后代是个未知数，不顾异性死活而挑起两性对立实则是人类自取灭亡的前兆。我们应该减少无谓的使用场景，只有实在是人力难以完成、不适合人类作业（主要指对人身体伤害很大）的场景才让AI帮忙，比如互补性质的智慧城市和无人驾驶，智慧城市可以对城市资源作一个更好的调度，减轻交通堵塞状况，让人脑去计算成千上万条道路的状况数据明显是不切实际的，而无人驾驶能够减少马路杀手、疲劳驾驶，长途驾驶对于驾驶员来说是一种身体的煎熬，很难长时间精力高度集中，无人驾驶并不是没有人，因为指令需要人下达，只是驾驶方式发生颠覆。即使有了原则，一昧地对人类的好也并不是好事，我们很容易丢掉宝贵的忧患意识，何况物极必反，身为父母都不会对子女无限制的好，都是这个道理。仅仅是目前没有智能的科技，也已经将大多数人豢养在金丝笼里，手机、pc等等无不是，身在城市长大的我自身也是难以摆脱对他们的依赖，如果科技再拥有自主的、呈碾压人类态势的智能，到底是人在使用科技还是科技在奴役人类，那一景象真的令人寒颤。


        AI的产生，使我们逐渐越来越依赖它，我们将慢慢丧失属于自身的基本生存优势（假若突然没了手机电脑我们还能做什么）。著名英国学者奥卡姆早就提出了解决这一类问题的原则概念，若无必要勿增实体。我们是否真的需要AI替我们去做一些我们不能做的事情，能力并不是越强越好，AI来到了这个世界上是应该被赋予些使命的，首当其冲要解决的是，它的使命是什么，如果并没有什么只有AI能解决人类自己不能解决的使命，那么AI就不应该被赋予如此强的能力，目前为止，并没有发现有什么人类不能齐心解决的问题，我们应该朝着理解彼此信任彼此的方向努力。毕竟我们是同类，同类之间做到真正的和谐共处之后，则再去谈如何容纳其他生灵、AI生命，况且我们不需要太高的境界，同类之间平等的对待才该是我们努力的方向。
        宗教是从自然的提示中开悟总结而来的，记载了人与人、自然和谐共处的景象、方法等内容的典籍，大科学家西奥多•冯•卡门（Theodore von Kármán）也曾谈到，科学与宗教其实是出奇的统一，而这些典籍记载了许多珍贵的资料，我觉得是时候回头审视一下了，奉读一下珍贵的典籍，看看我们与最初出发的方向偏离了多少，看看我们创造的新事物是否真的如典籍中那般和谐地与这个世界相融，近些年我们好像在没有人性的科学道路上越走越远，如果我们连最为弥足珍贵的人文劝诫都要熟视无睹，我们丢弃的不仅是过去还有未来。



以下为阿西洛马AI原则详细内容，转自CSDN，https://blog.csdn.net/zbgjhy88/article/details/78583218



原则目前共23项，分为三大类，分别为：科研问题（Research Issues）、伦理和价值（Ethics and values）、更长期的问题（Longer-term Issues）。具体如下：
Research Issues科研问题
1) Research Goal: The goal of AI research should be to create not undirected intelligence, but beneficial intelligence.
   研究目的：AI研究的目标，应该是创造有益(于人类)而不是不受(人类)控制的智能。
2) Research Funding: Investments in AI should be accompanied by funding for research on ensuring its beneficial use, including thorny questions in computer science, economics, law, ethics, and social studies, such as:
   研究经费：投资AI应该有部份经费()用于研究如何确保有益地使用AI，包括计算机科学、经济学、法律、伦理以及社会研究中的棘手问题，比如：
   How can we make future AI systems highly robust, so that they do what we want without malfunctioning or getting hacked?
   如何使未来的AI系统高度健全(“鲁棒性”)，让系统按我们的要求运行，而不会发生故障或遭黑客入侵?
   How can we grow our prosperity through automation while maintaining people’s resources and purpose?
   如何通过自动化提升我们的繁荣程度，同时维持人类的资源和意志?
   How can we update our legal systems to be more fair and efficient, to keep pace with AI, and to manage the risks associated with AI?
   如何改进法制体系使其更公平和高效，能够跟得上AI的发展速度，并且能够控制AI带来的风险?
   What set of values should AI be aligned with, and what legal and ethical status should it have?
   AI应该归属于什么样的价值体系?它该具有何种法律和伦理地位?
3) Science-Policy Link: There should be constructive and healthy exchange between AI researchers and policy-makers.
   科学与政策的联系：在AI研究者和政策制定者之间应该有建设性的、有益的交流。
4) Research Culture: A culture of cooperation, trust, and transparency should be fostered among researchers and developers of AI.
   科研文化：在AI研究者和开发者中应该培养一种合作、信任与透明的人文文化。
5) Race Avoidance: Teams developing AI systems should actively cooperate to avoid corner-cutting on safety standards.
   避免竞争：AI系统开发团队之间应该积极合作，以避免安全标准上的有机可乘。
   Ethics and values伦理和价值
6) Safety: AI systems should be safe and secure throughout their operational lifetime, and verifiably so where applicable and feasible.
   安全性：AI系统在它们整个运行过程中应该是安全和可靠的，而且其可应用性的和可行性应当接受验证。
7) Failure Transparency: If an AI system causes harm, it should be possible to ascertain why.
   故障透明性：如果一个AI系统造成了损害，那么造成损害的原因要能被确定。
8) Judicial Transparency: Any involvement by an autonomous system in judicial decision-making should provide a satisfactory explanation auditable by a competent human authority.
   司法透明性：任何自动系统参与的司法判决都应提供令人满意的司法解释以被相关领域的专家接受。
9) Responsibility: Designers and builders of advanced AI systems are stakeholders in the moral implications of their use, misuse, and actions, with a responsibility and opportunity to shape those implications.
   责任：高级AI系统的设计者和建造者，是AI使用、误用和行为所产生的道德影响的参与者，有责任和机会去塑造那些道德影响。
10) Value Alignment: Highly autonomous AI systems should be designed so that their goals and behaviors can be assured to align with human values throughout their operation.
    价值归属：高度自主的AI系统的设计，应该确保它们的目标和行为在整个运行中与人类的价值观相一致。
11) Human Values: AI systems should be designed and operated so as to be compatible with ideals of human dignity, rights, freedoms, and cultural diversity.
    人类价值观：AI系统应该被设计和操作，以使其和人类尊严、权力、自由和文化多样性的理想相一致。
12) Personal Privacy: People should have the right to access, manage and control the data they generate, given AI systems’ power to analyze and utilize that data.
    个人隐私：在给予AI系统以分析和使用数据的能力时，人们应该拥有权力去访问、管理和控制他们产生的数据。
13) Liberty and Privacy: The application of AI to personal data must not unreasonably curtail people’s real or perceived liberty.
    自由和隐私：AI在个人数据上的应用不能充许无理由地剥夺人们真实的或人们能感受到的自由。
14) Shared Benefit: AI technologies should benefit and empower as many people as possible.
    分享利益：AI科技应该惠及和服务尽可能多的人。
15) Shared Prosperity: The economic prosperity created by AI should be shared broadly, to benefit all of humanity.
    共同繁荣：由AI创造的经济繁荣应该被广泛地分享，惠及全人类。
16) Human Control: Humans should choose how and whether to delegate decisions to AI systems, to accomplish human-chosen objectives.
    人类控制：人类应该来选择如何和决定是否让AI系统去完成人类选择的目标。
17) Non-subversion: The power conferred by control of highly advanced AI systems should respect and improve, rather than subvert, the social and civic processes on which the health of society depends.
    非颠覆：高级AI被授予的权力应该尊重和改进健康的社会所依赖的社会和公民秩序，而不是颠覆。
18) AI Arms Race: An arms race in lethal autonomous weapons should be avoided.
    AI军备竞赛：致命的自动化武器的装备竞赛应该被避免。
    Longer-term Issues更长期的问题
19) Capability Caution: There being no consensus, we should avoid strong assumptions regarding upper limits on future AI capabilities.
    能力警惕：我们应该避免关于未来AI能力上限的过高假设，但这一点还没有达成共识。
20) Importance: Advanced AI could represent a profound change in the history of life on Earth, and should be planned for and managed with commensurate care and resources.
    重要性：高级AI能够代表地球生命历史的一个深刻变化，人类应该有相应的关切和资源来进行计划和管理。
21) Risks: Risks posed by AI systems, especially catastrophic or existential risks, must be subject to planning and mitigation efforts commensurate with their expected impact.
    风险：AI系统造成的风险，特别是灾难性的或有关人类存亡的风险，必须有针对性地计划和努力减轻可预见的冲击。
22) Recursive Self-Improvement: AI systems designed to recursively self-improve or self-replicate in a manner that could lead to rapidly increasing quality or quantity must be subject to strict safety and control measures.
    递归的自我提升：被设计成可以迅速提升质量和数量的方式进行递归自我升级或自我复制AI系统，必须受制于严格的安全和控制标准。
23) Common Good: Superintelligence should only be developed in the service of widely shared ethical ideals, and for the benefit of all humanity rather than one state or organization.
    公共利益：超级智能的开发是为了服务广泛认可的伦理观念，并且是为了全人类的利益而不是一个国家和组织的利益。